Certainly! Here's the updated `README.md` section with the **dataset link** included:

---

### ğŸ“š Dataset

This project uses a dataset from **Kaggle**:

* **Dataset Name**: [NER Annotated CVs](https://www.kaggle.com/datasets/mehyarmlaweh/ner-annotated-cvs)
* **Source**: Kaggle
* **Usage**: Resumes in PDF format are used for training the custom NER model and for testing resume ranking against job descriptions.

All resumes are anonymized and publicly available under the datasetâ€™s terms of use.

---

Now here is the **full updated `README.md`** with the dataset section integrated:

---

```markdown
# Automated Resume Analysis and Matching Using NLP and Custom NER

This project automates the process of resume screening using Natural Language Processing (NLP) and a custom Named Entity Recognition (NER) model built with spaCy. It processes PDF resumes, extracts structured information like Name, Email, Skills, Education, and Experience, and ranks them against a job description using TF-IDF and cosine similarity.

---

## ğŸ“Œ Features

- âœ… PDF text extraction using **PyMuPDF** and **Tesseract OCR**
- ğŸ§  Custom **spaCy NER** model for extracting resume entities
- ğŸ” Resume ranking using **TF-IDF** and **cosine similarity**
- ğŸ“Š Outputs include ranked results, JSON annotations, and model files
- ğŸ’¡ Designed to run on **Google Colab (Free Tier)** â€” no GPU needed

---

## ğŸ› ï¸ Technologies Used

- Python 3.x
- spaCy (custom NER model)
- PyMuPDF (PDF extraction)
- Tesseract OCR (scanned PDFs)
- scikit-learn (TF-IDF, similarity scoring)
- Google Colab (CPU-based runtime)

---

## ğŸ“š Dataset

This project uses a dataset from **Kaggle**:

- **Dataset Name**: [NER Annotated CVs](https://www.kaggle.com/datasets/mehyarmlaweh/ner-annotated-cvs)
- **Source**: Kaggle  
- **Usage**: Resumes in PDF format are used for training the custom NER model and for testing resume ranking against job descriptions.

All resumes are anonymized and publicly available under the datasetâ€™s terms of use.

---

## ğŸ“‚ Folder Structure

```

project/
â”‚
â”œâ”€â”€ resume\_analysis.py              # Main pipeline script
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample\_resumes/             # Folder with PDF resumes
â”‚   â””â”€â”€ job\_description.txt         # Role/job description for matching
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ner\_model/                  # Trained spaCy NER model
â”‚
â””â”€â”€ outputs/
â”œâ”€â”€ annotations/                # JSON outputs of extracted entities
â””â”€â”€ rankings/                   # Ranked resumes with similarity scores

````

---

## ğŸš€ How to Run

### 1. Clone the Repository
```bash
git clone https://github.com/YOUR_USERNAME/automated-resume-analysis.git
cd automated-resume-analysis
````

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run the Script

You can either run it locally or on Google Colab (recommended for limited hardware).

```bash
python resume_analysis.py
```

### 4. Outputs

* Annotated entities are saved in JSON format.
* Trained model is stored in `models/ner_model/`.
* Ranked resume scores are printed to the console and saved in `outputs/rankings/`.

---

## ğŸ“ˆ Performance Highlights

* **5,050 resumes** processed in **4 hours 48 minutes** on free Google Colab CPU
* **NER F1-score**: 99.94% (Precision: 99.97%, Recall: 99.91%)
* **Resume Matching Time**: <10 minutes for 5,048 resumes
* **Top Similarity Score**: 0.1895 (TF-IDF + Cosine Similarity)

---

## âœ… Use Cases

* HR departments or startups needing low-cost resume filtering
* Educational or research projects on resume parsing and ranking
* Proof-of-concept ATS (Applicant Tracking System)

---

## ğŸ“„ License

This project is open-source and free to use for non-commercial purposes. For commercial licensing, please contact the author.

---

## ğŸ™ Acknowledgements

* Developed by Amit Dashgupta as part of MSc Dissertation at Dublin Business School
* Special thanks to [spaCy](https://spacy.io), [Tesseract](https://github.com/tesseract-ocr/tesseract), [scikit-learn](https://scikit-learn.org), and [Kaggle](https://www.kaggle.com) for dataset resources
